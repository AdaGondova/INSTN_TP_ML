{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi31YQKqMK7F"
   },
   "source": [
    "Alexandre CARRE*, Marvin LEROUSSEAU, Enzo BATTISTELLA <img align=\"right\" width=\"400\" height=\"40\" src=\"images/epu_ia_logo.png\"> <br> *alexandre.carre@gustaveroussy.fr (Notebook conception) <br> marvin.lerousseau@gustaveroussy.fr (Notebook revision) <br> enzo.battistella@gustaveroussy.fr (Notebook revision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0Fl5ZhMMK7Q"
   },
   "source": [
    "# TP2: FEATURES EXTRACTION-VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqFCacMwMK7W"
   },
   "source": [
    "In this notebook, you will learn how to extract radiomics features and visualize the important characteristics of the Dataset. First, download necessary materials for the afternoon practical sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujZ5cuPNMrah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EPU-IA-2021'...\r\n",
      "remote: Enumerating objects: 40, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (40/40), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (31/31), done.\u001B[K\r\n",
      "remote: Total 279 (delta 20), reused 29 (delta 9), pack-reused 239\u001B[K\r\n",
      "Receiving objects: 100% (279/279), 389.97 MiB | 5.80 MiB/s, done.\r\n",
      "Resolving deltas: 100% (35/35), done.\r\n",
      "Updating files: 100% (190/190), done.\r\n",
      "/media/acarre/Data/PythonProjects/EPU-IA-2021/version_google_colab/EPU-IA-2021/version_google_colab/EPU-IA-2021\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/RRouhi/EPU-IA-2021.git\n",
    "%cd EPU-IA-2021/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABi5RdLPMK7b"
   },
   "source": [
    "### Installation of dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4te7I-YMK7i",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: pyradiomics in /home/acarre/anaconda3/lib/python3.7/site-packages (3.0.1)\r\n",
      "Requirement already satisfied: seaborn in /home/acarre/anaconda3/lib/python3.7/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: SimpleITK in /home/acarre/anaconda3/lib/python3.7/site-packages (2.0.2)\r\n",
      "Requirement already satisfied: numpy in /home/acarre/anaconda3/lib/python3.7/site-packages (1.17.2)\r\n",
      "Requirement already satisfied: pandas in /home/acarre/anaconda3/lib/python3.7/site-packages (0.25.1)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pyradiomics) (1.12.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pyradiomics) (1.0.3)\r\n",
      "Requirement already satisfied: pykwalify>=1.6.0 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pyradiomics) (1.8.0)\r\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/acarre/anaconda3/lib/python3.7/site-packages (from seaborn) (3.1.1)\r\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/acarre/anaconda3/lib/python3.7/site-packages (from seaborn) (1.3.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.0)\r\n",
      "Requirement already satisfied: ruamel.yaml>=0.16.0 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pykwalify>=1.6.0->pyradiomics) (0.16.12)\r\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/acarre/anaconda3/lib/python3.7/site-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/acarre/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/acarre/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/acarre/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\r\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /home/acarre/anaconda3/lib/python3.7/site-packages (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics) (0.2.2)\r\n",
      "Requirement already satisfied: setuptools in /home/acarre/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyradiomics seaborn SimpleITK numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dz0iWBtJMK78",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Radiomics features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNo9no_VMK8C"
   },
   "source": [
    "#### import radiomics toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP6KYNTRMK8F"
   },
   "outputs": [],
   "source": [
    "from radiomics import featureextractor  # This module is used for interaction with pyradiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RnP8vV2MK8W"
   },
   "source": [
    "### 1) Setting up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmW-OCRfMK8Z"
   },
   "source": [
    "We will load 2 patients from the BratS dataset (Images and segmentations of brain tumors). The radiomics package will be used to extract a set of features, and the \"signatures\" will be compared."
   "The following function returns the data in sitk format and it allows you to load two test cases and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AxvfCt_MK8l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "def load_nii_volume_as_array(filename, with_header=False):\n",
    "    \"\"\"\n",
    "    load nifty image into numpy array [z,y,x] axis order\n",
    "    The output array shape is like [Depth, Height, Width]\n",
    "    :param filename: the input file name, should be *.nii or *.nii.gz\n",
    "    :param with_header: return header information\n",
    "    :return: a numpy data array or numpy data array with header if set to True\n",
    "    \"\"\"\n",
    "    img = sitk.ReadImage(filename)\n",
    "    data = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    if with_header:\n",
    "        origin, spacing, direction = img.GetOrigin(), img.GetSpacing(), img.GetDirection()\n",
    "        return data, (origin, spacing, direction)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "    \n",
    "def set_header_information(array, header):\n",
    "    \"\"\"\n",
    "    Function to set header information to an array.\n",
    "    :param array: array to set the header\n",
    "    :param header: header information will be a tuple with (origin, spacing, direction)\n",
    "    :return: an image in sitk format\n",
    "    \"\"\"\n",
    "    img = sitk.GetImageFromArray(array)\n",
    "    img.SetOrigin(header[0])\n",
    "    img.SetSpacing(header[1])\n",
    "    img.SetDirection(header[2])\n",
    "    return img\n",
    "\n",
    "\n",
    "# function to process one subject data and return output path\n",
    "def process_one_subject(src, count, image_type):\n",
    "    \"\"\"\n",
    "    Function to read one subject data from the general input directory specifying by the count number and image_type\n",
    "    :param src: general input directory of all data\n",
    "    :param count: patient to be read (same order as the glob function walk in the path)\n",
    "    :param image_type: specify the image type to be read, can be 't1ce', 't1', 'flair', 't2', 'seg'\n",
    "    :return: a dict for the 'seg' with key as type of seg and value as nD array. For image a nD array\n",
    "    \"\"\"\n",
    "    # add check range of count (depend of numbers of samples)\n",
    "    files = glob.glob(os.path.join(src, '**/*{}.nii.gz'.format(image_type)), recursive=True)\n",
    "    k = (len(files) - count) - 1\n",
    "    file = files[k]\n",
    "    print('Processing---', os.path.basename(file))\n",
    "\n",
    "    if any(x in image_type.lower() for x in ['t1ce', 't1', 'flair', 't2']):\n",
    "        normalized = zscore_normalize(file)\n",
    "        return normalized\n",
    "\n",
    "    if 'seg' in image_type.lower():\n",
    "        label_full, label_nec, label_core, label_et = [], [], [], []\n",
    "        for label_num in [1, 2, 4, 5]:\n",
    "            img, header = load_nii_volume_as_array(file, with_header=True)\n",
    "            if label_num == 5:\n",
    "                img[img != 0] = 1  # Region 1 => 1+2+3+4 complete tumor\n",
    "                label_full = set_header_information(img, header)\n",
    "            if label_num == 1:\n",
    "                img[img != 1] = 0  # only left necrosis\n",
    "                label_nec = set_header_information(img, header)\n",
    "            if label_num == 2:\n",
    "                img[img == 2] = 0  # turn edema to 0\n",
    "                img[img != 0] = 1  # only keep necrosis, ET, NET = Tumor core\n",
    "                label_core = set_header_information(img, header)\n",
    "            if label_num == 4:\n",
    "                img[img != 4] = 0  # only left ET\n",
    "                img[img == 4] = 1\n",
    "                label_et = set_header_information(img, header)\n",
    "        return {'label_full': label_full, 'label_nec': label_nec,\n",
    "                'label_core': label_core, 'label_et': label_et}\n",
    "\n",
    "\n",
    "def zscore_normalize(img_path, mask=None):\n",
    "    \"\"\"\n",
    "    Function to Z-Score normalize an image from an image filepath. It will normalize the target \n",
    "    image by subtracting the mean of the whole brain and dividing by the standard deviation.\n",
    "    :param img_path: target MR brain image path\n",
    "    :param mask: brain mask path for img\n",
    "    :return: Normalized image in sitk format\n",
    "    \"\"\"\n",
    "    img_data, header = load_nii_volume_as_array(img_path, with_header=True)\n",
    "    if mask is not None and isinstance(mask, str):\n",
    "        mask_data = load_nii_volume_as_array(mask, with_header=False)\n",
    "    elif mask == 'nomask':\n",
    "        mask_data = img_data == img_data\n",
    "    else:\n",
    "        mask_data = img_data > img_data.mean()\n",
    "    logical_mask = mask_data == 1  # force the mask to be logical type\n",
    "    mean = img_data[logical_mask].mean()\n",
    "    std = img_data[logical_mask].std()\n",
    "    normalized_data = (img_data - mean) / std\n",
    "    normalized = set_header_information(normalized_data, header)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL_MOd6KMK8v"
   },
   "source": [
    "**Exercice:** Now load images from two patients with all their respective segmentations and apply normalization to MRI images. Then, save these new images. As a reminder the images of the BratS dataset have already been processed excluding from normalization. For your output filename, make sure to have an unique ID in the filename with the sequence name. \n",
    "\n",
    "Example :\n",
    "- For MRI modalities: id_modality_normalize.nii.gz (patient1_t1ce_normalize.nii.gz)\n",
    "- For Segmentations : id_seg_segtype.nii.gz (patient1_seg_nec.nii.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code Here\n",
    "\n",
    "# src =\n",
    "#\n",
    "# patient1_t1 =\n",
    "# patient1_t1_normalize_path =\n",
    "# sitk.WriteImage(patient1_t1, patient1_t1_normalize_path)\n",
    "#\n",
    "# patient1_t1ce =\n",
    "#\n",
    "# patient1_t2 =\n",
    "\n",
    "\n",
    "# ..... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG84YOAkMK8y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing--- TCGA-CS-6188_2001.08.12_t1.nii.gz\n",
      "Processing--- TCGA-CS-6188_2001.08.12_t1ce.nii.gz\n",
      "Processing--- TCGA-CS-6188_2001.08.12_t2.nii.gz\n",
      "Processing--- TCGA-CS-6188_2001.08.12_flair.nii.gz\n",
      "Processing--- TCGA-CS-6188_2001.08.12_seg.nii.gz\n",
      "Processing--- TCGA-CS-6186_2000.06.01_t1.nii.gz\n",
      "Processing--- TCGA-CS-6186_2000.06.01_t1ce.nii.gz\n",
      "Processing--- TCGA-CS-6186_2000.06.01_t2.nii.gz\n",
      "Processing--- TCGA-CS-6186_2000.06.01_flair.nii.gz\n",
      "Processing--- TCGA-CS-6186_2000.06.01_seg.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#@title Solution {display-mode: \"form\"}\n",
    "# %load solutions_exercices/2patients.py\n",
    "\n",
    "src = './data/preprocessed/'\n",
    "patient1_t1 = process_one_subject(src, count=0, image_type='t1')\n",
    "patient1_t1_normalize_path = 'patient1_t1_normalize.nii.gz'\n",
    "sitk.WriteImage(patient1_t1, patient1_t1_normalize_path)\n",
    "\n",
    "patient1_t1ce = process_one_subject(src, count=0, image_type='t1ce')\n",
    "patient1_tce1_normalize_path = 'patient1_t1ce_normalize.nii.gz'\n",
    "sitk.WriteImage(patient1_t1ce, patient1_tce1_normalize_path)\n",
    "\n",
    "patient1_t2 = process_one_subject(src, count=0, image_type='t2')\n",
    "patient1_t2_normalize_path = 'patient1_t2_normalize.nii.gz'\n",
    "sitk.WriteImage(patient1_t2, patient1_t2_normalize_path)\n",
    "\n",
    "patient1_flair = process_one_subject(src, count=0, image_type='flair')\n",
    "patient1_flair_normalize_path = 'patient1_flair_normalize.nii.gz'\n",
    "sitk.WriteImage(patient1_flair, patient1_flair_normalize_path)\n",
    "\n",
    "patient1_segmentations = process_one_subject(src, count=0, image_type='seg') # return a dict with {label_full, label_nec, label_core, label_et}\n",
    "patient1_seg_label_full_path = 'patient1_seg_label_full.nii.gz'\n",
    "sitk.WriteImage(patient1_segmentations['label_full'], patient1_seg_label_full_path)\n",
    "patient1_seg_label_nec_path = 'patient1_seg_label_nec.nii.gz'\n",
    "sitk.WriteImage(patient1_segmentations['label_nec'], patient1_seg_label_nec_path)\n",
    "patient1_seg_label_core_path = 'patient1_seg_label_core.nii.gz'\n",
    "sitk.WriteImage(patient1_segmentations['label_core'], patient1_seg_label_core_path)\n",
    "patient1_seg_label_et_path = 'patient1_seg_label_et.nii.gz'\n",
    "sitk.WriteImage(patient1_segmentations['label_et'], patient1_seg_label_et_path)\n",
    "\n",
    "\n",
    "patient2_t1 = process_one_subject(src, count=1, image_type='t1')\n",
    "patient2_t1_normalize_path = 'patient2_t1_normalize.nii.gz'\n",
    "sitk.WriteImage(patient2_t1, patient2_t1_normalize_path)\n",
    "\n",
    "patient2_t1ce = process_one_subject(src, count=1, image_type='t1ce')\n",
    "patient2_tce1_normalize_path = 'patient2_t1ce_normalize.nii.gz'\n",
    "sitk.WriteImage(patient2_t1ce, patient2_tce1_normalize_path)\n",
    "\n",
    "patient2_t2 = process_one_subject(src, count=1, image_type='t2')\n",
    "patient2_t2_normalize_path = 'patient2_t2_normalize.nii.gz'\n",
    "sitk.WriteImage(patient2_t2, patient2_t2_normalize_path)\n",
    "\n",
    "patient2_flair = process_one_subject(src, count=1, image_type='flair')\n",
    "patient2_flair_normalize_path = 'patient2_flair_normalize.nii.gz'\n",
    "sitk.WriteImage(patient2_flair, patient2_flair_normalize_path)\n",
    "\n",
    "patient2_segmentations = process_one_subject(src, count=1, image_type='seg')\n",
    "patient2_seg_label_full_path = 'patient2_seg_label_full.nii.gz'\n",
    "sitk.WriteImage(patient2_segmentations['label_full'], patient2_seg_label_full_path)\n",
    "patient2_seg_label_nec_path = 'patient2_seg_label_nec.nii.gz'\n",
    "sitk.WriteImage(patient2_segmentations['label_nec'], patient2_seg_label_nec_path)\n",
    "patient2_seg_label_core_path = 'patient2_seg_label_core.nii.gz'\n",
    "sitk.WriteImage(patient2_segmentations['label_core'], patient2_seg_label_core_path)\n",
    "patient2_seg_label_et_path = 'patient2_seg_label_et.nii.gz'\n",
    "sitk.WriteImage(patient2_segmentations['label_et'], patient2_seg_label_et_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gczujo3tMK86"
   },
   "source": [
    "### 2) Start the extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBMYxxFAMK9B"
   },
   "source": [
    "Now that we have our input, we need to define the parameters and instantiate the extractor. For this there are three possibilities:\n",
    " 1. Use defaults, don't define custom settings\n",
    " 2. Define parameters in a dictionary, control filters and features after initialisation\n",
    " 3. Use a parameter file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxIDADgvMK9J"
   },
   "source": [
    "#### Method 1: use defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSIoiLJjMK9P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction parameters:\n",
      "\t {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True}\n",
      "Enabled filters:\n",
      "\t {'Original': {}}\n",
      "Enabled features:\n",
      "\t {'firstorder': [], 'glcm': [], 'gldm': [], 'glrlm': [], 'glszm': [], 'ngtdm': [], 'shape': []}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "print('Extraction parameters:\\n\\t', extractor.settings)\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWn-5wk1MK9i"
   },
   "source": [
    "#### Method 2: hard-coded settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEMhQwMaMK9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction parameters:\n",
      "\t {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 20, 'sigma': [1, 2, 3]}\n",
      "Enabled filters:\n",
      "\t {'Original': {}}\n",
      "Enabled features:\n",
      "\t {'firstorder': [], 'glcm': [], 'gldm': [], 'glrlm': [], 'glszm': [], 'ngtdm': [], 'shape': []}\n"
     ]
    }
   ],
   "source": [
    "# First define the settings\n",
    "settings = {}\n",
    "settings['binWidth'] = 20\n",
    "settings['sigma'] = [1, 2, 3]\n",
    "\n",
    "# Instantiate the extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(**settings)  # ** 'unpacks' the dictionary in the function call\n",
    "\n",
    "print('Extraction parameters:\\n\\t', extractor.settings)\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)  # Still the default parameters\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)  # Still the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egeUbiFsMK99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction parameters:\n",
      "\t {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 20, 'sigma': [1, 2, 3]}\n",
      "Enabled filters:\n",
      "\t {'Original': {}}\n",
      "Enabled features:\n",
      "\t {'firstorder': [], 'glcm': [], 'gldm': [], 'glrlm': [], 'glszm': [], 'ngtdm': [], 'shape': []}\n"
     ]
    }
   ],
   "source": [
    "# This cell is equivalent to the previous cell\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(binWidth=20, sigma=[1, 2, 3])  # Equivalent of code above\n",
    "\n",
    "print('Extraction parameters:\\n\\t', extractor.settings)\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)  # Still the default parameters\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)  # Still the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zh7NsjiMK-M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enabled filters:\n",
      "\t {'Original': {}, 'LoG': {}}\n",
      "\n",
      "Enabled features:\n",
      "\t {'firstorder': []}\n",
      "\n",
      "Enabled features:\n",
      "\t {'firstorder': [], 'glcm': ['Autocorrelation', 'Homogeneity1', 'SumSquares']}\n"
     ]
    }
   ],
   "source": [
    "# Enable a filter (in addition to the 'Original' filter already enabled)\n",
    "extractor.enableImageTypeByName('LoG')\n",
    "print('')\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)\n",
    "\n",
    "# Disable all feature classes, save firstorder\n",
    "extractor.disableAllFeatures()\n",
    "extractor.enableFeatureClassByName('firstorder')\n",
    "print('')\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)\n",
    "\n",
    "# Specify some additional features in the GLCM feature class\n",
    "extractor.enableFeaturesByName(glcm=['Autocorrelation', 'Homogeneity1', 'SumSquares'])\n",
    "print('')\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaI_ZThZMK-Y"
   },
   "source": [
    "#### Method 3: using a parameter file¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZx4veXrMK-a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file, absolute path: /media/acarre/Data/PythonProjects/EPU-IA-2021/version_google_colab/EPU-IA-2021/version_google_colab/EPU-IA-2021/exampleSettings/Params.yaml\n"
     ]
    }
   ],
   "source": [
    "# Additonally, store the location of the example parameter file /exampleSettings/Params.yaml\n",
    "paramPath = os.path.join('exampleSettings', 'Params.yaml')\n",
    "print('Parameter file, absolute path:', os.path.abspath(paramPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cgi-auNMK-j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction parameters:\n",
      "\t {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 25, 'weightingNorm': None}\n",
      "Enabled filters:\n",
      "\t {'Original': {}}\n",
      "Enabled features:\n",
      "\t {'shape': None, 'firstorder': [], 'glcm': ['Autocorrelation', 'JointAverage', 'ClusterProminence', 'ClusterShade', 'ClusterTendency', 'Contrast', 'Correlation', 'DifferenceAverage', 'DifferenceEntropy', 'DifferenceVariance', 'JointEnergy', 'JointEntropy', 'Imc1', 'Imc2', 'Idm', 'Idmn', 'Id', 'Idn', 'InverseVariance', 'MaximumProbability', 'SumEntropy', 'SumSquares'], 'glrlm': None, 'glszm': None, 'gldm': None}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(paramPath)\n",
    "\n",
    "print('Extraction parameters:\\n\\t', extractor.settings)\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm0n0CnmMK-w"
   },
   "source": [
    "###  Extract features¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqLL9oYeMK-1"
   },
   "source": [
    "Now that we have our extractor set up with the correct parameters, we can start extracting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8S3xxmEMK-6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('diagnostics_Versions_PyRadiomics', 'v3.0.1'), ('diagnostics_Versions_Numpy', '1.17.2'), ('diagnostics_Versions_SimpleITK', '2.0.2'), ('diagnostics_Versions_PyWavelet', '1.0.3'), ('diagnostics_Versions_Python', '3.7.4'), ('diagnostics_Configuration_Settings', {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 25, 'weightingNorm': None}), ('diagnostics_Configuration_EnabledImageTypes', {'Original': {}}), ('diagnostics_Image-original_Hash', '9b254c88bd7c5dce806b5c3b096441635b242bdc'), ('diagnostics_Image-original_Dimensionality', '3D'), ('diagnostics_Image-original_Spacing', (1.0, 1.0, 1.0)), ('diagnostics_Image-original_Size', (240, 240, 155)), ('diagnostics_Image-original_Mean', -3.2388073481968083), ('diagnostics_Image-original_Minimum', -3.9469088572376285), ('diagnostics_Image-original_Maximum', 10.879673454083735), ('diagnostics_Mask-original_Hash', '854e13e7b95928c8268a22517a7a8b3d1eb2d7c5'), ('diagnostics_Mask-original_Spacing', (1.0, 1.0, 1.0)), ('diagnostics_Mask-original_Size', (240, 240, 155)), ('diagnostics_Mask-original_BoundingBox', (134, 148, 40, 52, 68, 70)), ('diagnostics_Mask-original_VoxelNum', 30073), ('diagnostics_Mask-original_VolumeNum', 21), ('diagnostics_Mask-original_CenterOfMassIndex', (163.4712865360955, 182.95750340837296, 75.82732018754365)), ('diagnostics_Mask-original_CenterOfMass', (163.4712865360955, -56.04249659162704, 75.82732018754365)), ('original_shape_Elongation', 0.8088851113146104), ('original_shape_Flatness', 0.3779577153085302), ('original_shape_LeastAxisLength', 21.667608179505102), ('original_shape_MajorAxisLength', 57.32812772936158), ('original_shape_Maximum2DDiameterColumn', array(69.72087205)), ('original_shape_Maximum2DDiameterRow', array(65.12296062)), ('original_shape_Maximum2DDiameterSlice', array(79.64923101)), ('original_shape_Maximum3DDiameter', array(84.58132182)), ('original_shape_MeshVolume', array(29775.79166667)), ('original_shape_MinorAxisLength', 46.37186897982284), ('original_shape_Sphericity', array(0.40144207)), ('original_shape_SurfaceArea', array(11572.75572445)), ('original_shape_SurfaceVolumeRatio', array(0.38866324)), ('original_shape_VoxelVolume', 30073.0), ('original_firstorder_10Percentile', array(-0.00712028)), ('original_firstorder_90Percentile', array(1.25341297)), ('original_firstorder_Energy', array(33031.50618197)), ('original_firstorder_Entropy', array(0.47295691)), ('original_firstorder_InterquartileRange', array(0.63619418)), ('original_firstorder_Kurtosis', array(17.6452626)), ('original_firstorder_Maximum', array(1.99512669)), ('original_firstorder_MeanAbsoluteDeviation', array(0.50723195)), ('original_firstorder_Mean', array(0.53070123)), ('original_firstorder_Median', array(0.66753514)), ('original_firstorder_Minimum', array(-3.90211282)), ('original_firstorder_Range', array(5.89723952)), ('original_firstorder_RobustMeanAbsoluteDeviation', array(0.26389262)), ('original_firstorder_RootMeanSquared', array(1.04803506)), ('original_firstorder_Skewness', array(-3.48108196)), ('original_firstorder_TotalEnergy', array(33031.50618197)), ('original_firstorder_Uniformity', array(0.81799736)), ('original_firstorder_Variance', array(0.8167337)), ('original_glcm_Autocorrelation', array(3.72548187)), ('original_glcm_JointAverage', array(1.91825372)), ('original_glcm_ClusterProminence', array(0.62439552)), ('original_glcm_ClusterShade', array(-0.35467558)), ('original_glcm_ClusterTendency', array(0.24159497)), ('original_glcm_Contrast', array(0.05855857)), ('original_glcm_Correlation', array(0.60625393)), ('original_glcm_DifferenceAverage', array(0.05855857)), ('original_glcm_DifferenceEntropy', array(0.32015172)), ('original_glcm_DifferenceVariance', array(0.05501543)), ('original_glcm_JointEnergy', array(0.7949078)), ('original_glcm_JointEntropy', array(0.66969096)), ('original_glcm_Imc1', array(-0.35606981)), ('original_glcm_Imc2', array(0.49748703)), ('original_glcm_Idm', array(0.97072071)), ('original_glcm_Idmn', array(0.98828829)), ('original_glcm_Id', array(0.97072071)), ('original_glcm_Idn', array(0.98048048)), ('original_glcm_InverseVariance', array(0.05855857)), ('original_glcm_MaximumProbability', array(0.88897443)), ('original_glcm_SumEntropy', array(0.61113239)), ('original_glcm_SumSquares', array(0.07503839)), ('original_glrlm_GrayLevelNonUniformity', array(3000.81588306)), ('original_glrlm_GrayLevelNonUniformityNormalized', array(0.56843411)), ('original_glrlm_GrayLevelVariance', array(0.21578295)), ('original_glrlm_HighGrayLevelRunEmphasis', array(3.0541676)), ('original_glrlm_LongRunEmphasis', array(79.8779344)), ('original_glrlm_LongRunHighGrayLevelEmphasis', array(314.33951917)), ('original_glrlm_LongRunLowGrayLevelEmphasis', array(21.2625382)), ('original_glrlm_LowGrayLevelRunEmphasis', array(0.4864581)), ('original_glrlm_RunEntropy', array(4.3242074)), ('original_glrlm_RunLengthNonUniformity', array(695.44606867)), ('original_glrlm_RunLengthNonUniformityNormalized', array(0.12764085)), ('original_glrlm_RunPercentage', array(0.17528885)), ('original_glrlm_RunVariance', array(42.9107552)), ('original_glrlm_ShortRunEmphasis', array(0.32741217)), ('original_glrlm_ShortRunHighGrayLevelEmphasis', array(0.74376469)), ('original_glrlm_ShortRunLowGrayLevelEmphasis', array(0.22332404)), ('original_glszm_GrayLevelNonUniformity', array(34.89473684)), ('original_glszm_GrayLevelNonUniformityNormalized', array(0.61218837)), ('original_glszm_GrayLevelVariance', array(0.19390582)), ('original_glszm_HighGrayLevelZoneEmphasis', array(1.78947368)), ('original_glszm_LargeAreaEmphasis', array(12713757.94736842)), ('original_glszm_LargeAreaHighGrayLevelEmphasis', array(50702562.36842106)), ('original_glszm_LargeAreaLowGrayLevelEmphasis', array(3216556.84210526)), ('original_glszm_LowGrayLevelZoneEmphasis', array(0.80263158)), ('original_glszm_SizeZoneNonUniformity', array(5.38596491)), ('original_glszm_SizeZoneNonUniformityNormalized', array(0.09449061)), ('original_glszm_SmallAreaEmphasis', array(0.29051882)), ('original_glszm_SmallAreaHighGrayLevelEmphasis', array(0.58761696)), ('original_glszm_SmallAreaLowGrayLevelEmphasis', array(0.21624428)), ('original_glszm_ZoneEntropy', array(4.65291842)), ('original_glszm_ZonePercentage', array(0.00189539)), ('original_glszm_ZoneVariance', array(12435399.88981225)), ('original_gldm_DependenceEntropy', array(3.58569832)), ('original_gldm_DependenceNonUniformity', array(6907.15615336)), ('original_gldm_DependenceNonUniformityNormalized', array(0.22967965)), ('original_gldm_DependenceVariance', array(34.77514004)), ('original_gldm_GrayLevelNonUniformity', array(24599.63452266)), ('original_gldm_GrayLevelVariance', array(0.09100132)), ('original_gldm_HighGrayLevelEmphasis', array(3.69623915)), ('original_gldm_LargeDependenceEmphasis', array(538.4404948)), ('original_gldm_LargeDependenceHighGrayLevelEmphasis', array(2095.47750474)), ('original_gldm_LargeDependenceLowGrayLevelEmphasis', array(149.18124231)), ('original_gldm_LowGrayLevelEmphasis', array(0.32594021)), ('original_gldm_SmallDependenceEmphasis', array(0.00404579)), ('original_gldm_SmallDependenceHighGrayLevelEmphasis', array(0.01126746)), ('original_gldm_SmallDependenceLowGrayLevelEmphasis', array(0.00224037))])\n"
     ]
    }
   ],
   "source": [
    "imagePath = patient1_t1_normalize_path\n",
    "maskPath = patient1_seg_label_full_path\n",
    "\n",
    "result = extractor.execute(imagePath, maskPath)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KWgzJT3MK_M"
   },
   "source": [
    "As you may have already seen, Pyradiomics returns an ordered dict that is visually not very pleasant. We can then turn this result into a pandas format. The keys in the dictionary will be used as the index (labels for the rows), with the values of the features as the values in the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82AK29bsMK_N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo5V6ZETMK_V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostics_Versions_PyRadiomics                                                                 v3.0.1\n",
      "diagnostics_Versions_Numpy                                                                       1.17.2\n",
      "diagnostics_Versions_SimpleITK                                                                    2.0.2\n",
      "diagnostics_Versions_PyWavelet                                                                    1.0.3\n",
      "diagnostics_Versions_Python                                                                       3.7.4\n",
      "diagnostics_Configuration_Settings                    {'minimumROIDimensions': 2, 'minimumROISize': ...\n",
      "diagnostics_Configuration_EnabledImageTypes                                            {'Original': {}}\n",
      "diagnostics_Image-original_Hash                                9b254c88bd7c5dce806b5c3b096441635b242bdc\n",
      "diagnostics_Image-original_Dimensionality                                                            3D\n",
      "diagnostics_Image-original_Spacing                                                      (1.0, 1.0, 1.0)\n",
      "diagnostics_Image-original_Size                                                         (240, 240, 155)\n",
      "diagnostics_Image-original_Mean                                                                -3.23881\n",
      "diagnostics_Image-original_Minimum                                                             -3.94691\n",
      "diagnostics_Image-original_Maximum                                                              10.8797\n",
      "diagnostics_Mask-original_Hash                                 854e13e7b95928c8268a22517a7a8b3d1eb2d7c5\n",
      "diagnostics_Mask-original_Spacing                                                       (1.0, 1.0, 1.0)\n",
      "diagnostics_Mask-original_Size                                                          (240, 240, 155)\n",
      "diagnostics_Mask-original_BoundingBox                                        (134, 148, 40, 52, 68, 70)\n",
      "diagnostics_Mask-original_VoxelNum                                                                30073\n",
      "diagnostics_Mask-original_VolumeNum                                                                  21\n",
      "diagnostics_Mask-original_CenterOfMassIndex           (163.4712865360955, 182.95750340837296, 75.827...\n",
      "diagnostics_Mask-original_CenterOfMass                (163.4712865360955, -56.04249659162704, 75.827...\n",
      "original_shape_Elongation                                                                      0.808885\n",
      "original_shape_Flatness                                                                        0.377958\n",
      "original_shape_LeastAxisLength                                                                  21.6676\n",
      "original_shape_MajorAxisLength                                                                  57.3281\n",
      "original_shape_Maximum2DDiameterColumn                                                69.72087205421343\n",
      "original_shape_Maximum2DDiameterRow                                                   65.12296062065974\n",
      "original_shape_Maximum2DDiameterSlice                                                 79.64923100695951\n",
      "original_shape_Maximum3DDiameter                                                        84.581321815162\n",
      "original_shape_MeshVolume                                                            29775.791666666668\n",
      "original_shape_MinorAxisLength                                                                  46.3719\n",
      "original_shape_Sphericity                                                           0.40144206969101914\n",
      "original_shape_SurfaceArea                                                           11572.755724454999\n",
      "original_shape_SurfaceVolumeRatio                                                   0.38866324207293673\n",
      "original_shape_VoxelVolume                                                                        30073\n",
      "original_firstorder_10Percentile                                                 -0.0071202838352694055\n",
      "original_firstorder_90Percentile                                                     1.2534129661686686\n",
      "original_firstorder_Energy                                                           33031.506181972254\n",
      "original_firstorder_Entropy                                                         0.47295691345861357\n",
      "original_firstorder_InterquartileRange                                                0.636194181027187\n",
      "original_firstorder_Kurtosis                                                         17.645262595713458\n",
      "original_firstorder_Maximum                                                          1.9951266941485872\n",
      "original_firstorder_MeanAbsoluteDeviation                                            0.5072319478399978\n",
      "original_firstorder_Mean                                                             0.5307012269439779\n",
      "original_firstorder_Median                                                           0.6675351385769183\n",
      "original_firstorder_Minimum                                                          -3.902112823153922\n",
      "original_firstorder_Range                                                             5.897239517302509\n",
      "original_firstorder_RobustMeanAbsoluteDeviation                                      0.2638926195213857\n",
      "original_firstorder_RootMeanSquared                                                  1.0480350602497963\n",
      "original_firstorder_Skewness                                                        -3.4810819648344276\n",
      "original_firstorder_TotalEnergy                                                      33031.506181972254\n",
      "original_firstorder_Uniformity                                                       0.8179973571862309\n",
      "original_firstorder_Variance                                                         0.8167336952329503\n",
      "original_glcm_Autocorrelation                                                        3.7254818726074683\n",
      "original_glcm_JointAverage                                                           1.9182537196680882\n",
      "original_glcm_ClusterProminence                                                      0.6243955157770713\n",
      "original_glcm_ClusterShade                                                         -0.35467557574303854\n",
      "original_glcm_ClusterTendency                                                       0.24159497086495416\n",
      "original_glcm_Contrast                                                             0.058558572793593076\n",
      "original_glcm_Correlation                                                            0.6062539280869643\n",
      "original_glcm_DifferenceAverage                                                    0.058558572793593076\n",
      "original_glcm_DifferenceEntropy                                                      0.3201517241082849\n",
      "original_glcm_DifferenceVariance                                                    0.05501542628670039\n",
      "original_glcm_JointEnergy                                                             0.794907801884026\n",
      "original_glcm_JointEntropy                                                           0.6696909599323946\n",
      "original_glcm_Imc1                                                                  -0.3560698141057672\n",
      "original_glcm_Imc2                                                                   0.4974870299468704\n",
      "original_glcm_Idm                                                                    0.9707207136032033\n",
      "original_glcm_Idmn                                                                   0.9882882854412814\n",
      "original_glcm_Id                                                                     0.9707207136032033\n",
      "original_glcm_Idn                                                                     0.980480475735469\n",
      "original_glcm_InverseVariance                                                      0.058558572793593076\n",
      "original_glcm_MaximumProbability                                                     0.8889744332712918\n",
      "original_glcm_SumEntropy                                                             0.6111323871388017\n",
      "original_glcm_SumSquares                                                            0.07503838591463681\n",
      "original_glrlm_GrayLevelNonUniformity                                                 3000.815883061912\n",
      "original_glrlm_GrayLevelNonUniformityNormalized                                      0.5684341082551094\n",
      "original_glrlm_GrayLevelVariance                                                     0.2157829458724453\n",
      "original_glrlm_HighGrayLevelRunEmphasis                                               3.054167601508515\n",
      "original_glrlm_LongRunEmphasis                                                        79.87793439879722\n",
      "original_glrlm_LongRunHighGrayLevelEmphasis                                          314.33951917420876\n",
      "original_glrlm_LongRunLowGrayLevelEmphasis                                           21.262538204944352\n",
      "original_glrlm_LowGrayLevelRunEmphasis                                               0.4864580996228712\n",
      "original_glrlm_RunEntropy                                                             4.324207395427617\n",
      "original_glrlm_RunLengthNonUniformity                                                 695.4460686661334\n",
      "original_glrlm_RunLengthNonUniformityNormalized                                     0.12764085262596422\n",
      "original_glrlm_RunPercentage                                                         0.1752888484175685\n",
      "original_glrlm_RunVariance                                                            42.91075519529453\n",
      "original_glrlm_ShortRunEmphasis                                                     0.32741216892968605\n",
      "original_glrlm_ShortRunHighGrayLevelEmphasis                                         0.7437646901045394\n",
      "original_glrlm_ShortRunLowGrayLevelEmphasis                                         0.22332403863597264\n",
      "original_glszm_GrayLevelNonUniformity                                                 34.89473684210526\n",
      "original_glszm_GrayLevelNonUniformityNormalized                                      0.6121883656509696\n",
      "original_glszm_GrayLevelVariance                                                    0.19390581717451522\n",
      "original_glszm_HighGrayLevelZoneEmphasis                                             1.7894736842105263\n",
      "original_glszm_LargeAreaEmphasis                                                      12713757.94736842\n",
      "original_glszm_LargeAreaHighGrayLevelEmphasis                                        50702562.368421055\n",
      "original_glszm_LargeAreaLowGrayLevelEmphasis                                         3216556.8421052634\n",
      "original_glszm_LowGrayLevelZoneEmphasis                                              0.8026315789473685\n",
      "original_glszm_SizeZoneNonUniformity                                                  5.385964912280702\n",
      "original_glszm_SizeZoneNonUniformityNormalized                                      0.09449061249615266\n",
      "original_glszm_SmallAreaEmphasis                                                     0.2905188199011448\n",
      "original_glszm_SmallAreaHighGrayLevelEmphasis                                        0.5876169602193619\n",
      "original_glszm_SmallAreaLowGrayLevelEmphasis                                        0.21624428482159058\n",
      "original_glszm_ZoneEntropy                                                            4.652918418266811\n",
      "original_glszm_ZonePercentage                                                     0.0018953878894689589\n",
      "original_glszm_ZoneVariance                                                          12435399.889812248\n",
      "original_gldm_DependenceEntropy                                                      3.5856983233921946\n",
      "original_gldm_DependenceNonUniformity                                                 6907.156153360157\n",
      "original_gldm_DependenceNonUniformityNormalized                                     0.22967965129385684\n",
      "original_gldm_DependenceVariance                                                      34.77514003768188\n",
      "original_gldm_GrayLevelNonUniformity                                                 24599.634522661523\n",
      "original_gldm_GrayLevelVariance                                                     0.09100132140688451\n",
      "original_gldm_HighGrayLevelEmphasis                                                  3.6962391513982644\n",
      "original_gldm_LargeDependenceEmphasis                                                 538.4404947959964\n",
      "original_gldm_LargeDependenceHighGrayLevelEmphasis                                   2095.4775047384696\n",
      "original_gldm_LargeDependenceLowGrayLevelEmphasis                                    149.18124231037808\n",
      "original_gldm_LowGrayLevelEmphasis                                                  0.32594021215043395\n",
      "original_gldm_SmallDependenceEmphasis                                              0.004045790832997119\n",
      "original_gldm_SmallDependenceHighGrayLevelEmphasis                                 0.011267459460195327\n",
      "original_gldm_SmallDependenceLowGrayLevelEmphasis                                  0.002240373676197567\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPo7haYZMK_e"
   },
   "source": [
    "Now we will use a loop to extract a set of features for our two patients with all their segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0T4T84RJMK_g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              Image                    Segmentation\n0      patient1_t1_normalize.nii.gz  patient1_seg_label_full.nii.gz\n1    patient1_t1ce_normalize.nii.gz  patient1_seg_label_full.nii.gz\n2      patient1_t2_normalize.nii.gz  patient1_seg_label_full.nii.gz\n3   patient1_flair_normalize.nii.gz  patient1_seg_label_full.nii.gz\n4      patient1_t1_normalize.nii.gz   patient1_seg_label_nec.nii.gz\n5    patient1_t1ce_normalize.nii.gz   patient1_seg_label_nec.nii.gz\n6      patient1_t2_normalize.nii.gz   patient1_seg_label_nec.nii.gz\n7   patient1_flair_normalize.nii.gz   patient1_seg_label_nec.nii.gz\n8      patient1_t1_normalize.nii.gz  patient1_seg_label_core.nii.gz\n9    patient1_t1ce_normalize.nii.gz  patient1_seg_label_core.nii.gz\n10     patient1_t2_normalize.nii.gz  patient1_seg_label_core.nii.gz\n11  patient1_flair_normalize.nii.gz  patient1_seg_label_core.nii.gz\n12     patient1_t1_normalize.nii.gz    patient1_seg_label_et.nii.gz\n13   patient1_t1ce_normalize.nii.gz    patient1_seg_label_et.nii.gz\n14     patient1_t2_normalize.nii.gz    patient1_seg_label_et.nii.gz\n15  patient1_flair_normalize.nii.gz    patient1_seg_label_et.nii.gz\n16     patient2_t1_normalize.nii.gz  patient2_seg_label_full.nii.gz\n17   patient2_t1ce_normalize.nii.gz  patient2_seg_label_full.nii.gz\n18     patient2_t2_normalize.nii.gz  patient2_seg_label_full.nii.gz\n19  patient2_flair_normalize.nii.gz  patient2_seg_label_full.nii.gz\n20     patient2_t1_normalize.nii.gz   patient2_seg_label_nec.nii.gz\n21   patient2_t1ce_normalize.nii.gz   patient2_seg_label_nec.nii.gz\n22     patient2_t2_normalize.nii.gz   patient2_seg_label_nec.nii.gz\n23  patient2_flair_normalize.nii.gz   patient2_seg_label_nec.nii.gz\n24     patient2_t1_normalize.nii.gz  patient2_seg_label_core.nii.gz\n25   patient2_t1ce_normalize.nii.gz  patient2_seg_label_core.nii.gz\n26     patient2_t2_normalize.nii.gz  patient2_seg_label_core.nii.gz\n27  patient2_flair_normalize.nii.gz  patient2_seg_label_core.nii.gz\n28     patient2_t1_normalize.nii.gz    patient2_seg_label_et.nii.gz\n29   patient2_t1ce_normalize.nii.gz    patient2_seg_label_et.nii.gz\n30     patient2_t2_normalize.nii.gz    patient2_seg_label_et.nii.gz\n31  patient2_flair_normalize.nii.gz    patient2_seg_label_et.nii.gz",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Segmentation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>patient1_t1_normalize.nii.gz</td>\n      <td>patient1_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>patient1_t1ce_normalize.nii.gz</td>\n      <td>patient1_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>patient1_t2_normalize.nii.gz</td>\n      <td>patient1_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>patient1_flair_normalize.nii.gz</td>\n      <td>patient1_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>patient1_t1_normalize.nii.gz</td>\n      <td>patient1_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>patient1_t1ce_normalize.nii.gz</td>\n      <td>patient1_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>patient1_t2_normalize.nii.gz</td>\n      <td>patient1_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>patient1_flair_normalize.nii.gz</td>\n      <td>patient1_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>patient1_t1_normalize.nii.gz</td>\n      <td>patient1_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>patient1_t1ce_normalize.nii.gz</td>\n      <td>patient1_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>patient1_t2_normalize.nii.gz</td>\n      <td>patient1_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>patient1_flair_normalize.nii.gz</td>\n      <td>patient1_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>patient1_t1_normalize.nii.gz</td>\n      <td>patient1_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>patient1_t1ce_normalize.nii.gz</td>\n      <td>patient1_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>patient1_t2_normalize.nii.gz</td>\n      <td>patient1_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>patient1_flair_normalize.nii.gz</td>\n      <td>patient1_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>patient2_t1_normalize.nii.gz</td>\n      <td>patient2_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>patient2_t1ce_normalize.nii.gz</td>\n      <td>patient2_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>patient2_t2_normalize.nii.gz</td>\n      <td>patient2_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>patient2_flair_normalize.nii.gz</td>\n      <td>patient2_seg_label_full.nii.gz</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>patient2_t1_normalize.nii.gz</td>\n      <td>patient2_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>patient2_t1ce_normalize.nii.gz</td>\n      <td>patient2_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>patient2_t2_normalize.nii.gz</td>\n      <td>patient2_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>patient2_flair_normalize.nii.gz</td>\n      <td>patient2_seg_label_nec.nii.gz</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>patient2_t1_normalize.nii.gz</td>\n      <td>patient2_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>patient2_t1ce_normalize.nii.gz</td>\n      <td>patient2_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>patient2_t2_normalize.nii.gz</td>\n      <td>patient2_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>patient2_flair_normalize.nii.gz</td>\n      <td>patient2_seg_label_core.nii.gz</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>patient2_t1_normalize.nii.gz</td>\n      <td>patient2_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>patient2_t1ce_normalize.nii.gz</td>\n      <td>patient2_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>patient2_t2_normalize.nii.gz</td>\n      <td>patient2_seg_label_et.nii.gz</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>patient2_flair_normalize.nii.gz</td>\n      <td>patient2_seg_label_et.nii.gz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The idea is to loop over image and associated segmentations\n",
    "# We choose to create a dataframe who associated both\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "patient1_segmentations_path = [patient1_seg_label_full_path, patient1_seg_label_nec_path, patient1_seg_label_core_path, patient1_seg_label_et_path]\n",
    "patient2_segmentations_path = [patient2_seg_label_full_path, patient2_seg_label_nec_path, patient2_seg_label_core_path, patient2_seg_label_et_path]\n",
    "patient1_images_path = [patient1_t1_normalize_path, patient1_tce1_normalize_path, patient1_t2_normalize_path, patient1_flair_normalize_path]\n",
    "patient2_images_path = [patient2_t1_normalize_path, patient2_tce1_normalize_path, patient2_t2_normalize_path, patient2_flair_normalize_path]\n",
    "\n",
    "# For a segmentation, we have 4 MRI sequences\n",
    "\n",
    "segmentations  = [item for item in patient1_segmentations_path for i in range(4)] + [item for item in patient2_segmentations_path for i in range(4)]\n",
    "images = patient1_images_path * 4 + patient2_images_path * 4\n",
    "\n",
    "# Now we construct a DataFrame from our two list\n",
    "data = {'Image':  images,\n",
    "        'Segmentation': segmentations,\n",
    "        }\n",
    "\n",
    "database_df = pd.DataFrame (data, columns = data.keys())\n",
    "display(database_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLEMvYXnMK_s",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process:   ----   Image:  patient1_t1_normalize.nii.gz  Segmentation:  patient1_seg_label_full.nii.gz\n",
      "process:   ----   Image:  patient1_t1ce_normalize.nii.gz  Segmentation:  patient1_seg_label_full.nii.gz\n",
      "process:   ----   Image:  patient1_t2_normalize.nii.gz  Segmentation:  patient1_seg_label_full.nii.gz\n",
      "process:   ----   Image:  patient1_flair_normalize.nii.gz  Segmentation:  patient1_seg_label_full.nii.gz\n",
      "process:   ----   Image:  patient1_t1_normalize.nii.gz  Segmentation:  patient1_seg_label_nec.nii.gz\n",
      "process:   ----   Image:  patient1_t1ce_normalize.nii.gz  Segmentation:  patient1_seg_label_nec.nii.gz\n",
      "process:   ----   Image:  patient1_t2_normalize.nii.gz  Segmentation:  patient1_seg_label_nec.nii.gz\n",
      "process:   ----   Image:  patient1_flair_normalize.nii.gz  Segmentation:  patient1_seg_label_nec.nii.gz\n",
      "process:   ----   Image:  patient1_t1_normalize.nii.gz  Segmentation:  patient1_seg_label_core.nii.gz\n",
      "process:   ----   Image:  patient1_t1ce_normalize.nii.gz  Segmentation:  patient1_seg_label_core.nii.gz\n",
      "process:   ----   Image:  patient1_t2_normalize.nii.gz  Segmentation:  patient1_seg_label_core.nii.gz\n",
      "process:   ----   Image:  patient1_flair_normalize.nii.gz  Segmentation:  patient1_seg_label_core.nii.gz\n",
      "process:   ----   Image:  patient1_t1_normalize.nii.gz  Segmentation:  patient1_seg_label_et.nii.gz\n",
      "process:   ----   Image:  patient1_t1ce_normalize.nii.gz  Segmentation:  patient1_seg_label_et.nii.gz\n",
      "process:   ----   Image:  patient1_t2_normalize.nii.gz  Segmentation:  patient1_seg_label_et.nii.gz\n",
      "process:   ----   Image:  patient1_flair_normalize.nii.gz  Segmentation:  patient1_seg_label_et.nii.gz\n",
      "process:   ----   Image:  patient2_t1_normalize.nii.gz  Segmentation:  patient2_seg_label_full.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# We construct the loop to extract features from our Database generated DataFrame\n",
    "from radiomics import featureextractor\n",
    "\n",
    "paramPath = os.path.join('exampleSettings', 'Params.yaml')\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(paramPath)\n",
    "\n",
    "results_extraction = pd.DataFrame()\n",
    "for row_idx, row in database_df.iterrows():\n",
    "    print('process:'  '   ----   ' 'Image: ', row['Image'], ' Segmentation: ', row['Segmentation'])\n",
    "    result_extraction = pd.Series(extractor.execute(row['Image'], row['Segmentation']))\n",
    "    feature_vector = (pd.Series(row)).append(result_extraction)\n",
    "    feature_vector.name = row_idx\n",
    "    results_extraction = results_extraction.join(feature_vector, how='outer')\n",
    "    \n",
    "# Transpose DataFrame to have one row by analysis\n",
    "results_extraction = results_extraction.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynx9K8h8MK_1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# One row per image/segmentation, features ares columns\n",
    "from IPython.display import display\n",
    "\n",
    "display(results_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORQ0hB4SMK__"
   },
   "source": [
    "Now, you have an example of extracted set of features corresponding to two patients and their respective modalities and segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VuBHlZ7MLAB"
   },
   "source": [
    "### Signatures comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azuQJXfAMLAH"
   },
   "source": [
    "Now, let's compare the signatures for our two patients..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0KYRhhyMLAJ"
   },
   "source": [
    "#### Prepare for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RB2uqMMRMLAK"
   },
   "source": [
    "Because we'd like to plot the feature vectors, create numpy arrays for features starting with original_ (excluding meta-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slwa_2a8MLAN",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding some cleaning in the generated dataframe\n",
    "patient = results_extraction['Image'].str.split('_').str[0]\n",
    "sequence = results_extraction['Image'].str.split('_').str[1]\n",
    "segtype = results_extraction['Segmentation'].str.split('_').str[-1].str.split('.').str[0]\n",
    "features_columns = [col for col in results_extraction if col.startswith('original')]\n",
    "dataframe_cleaned = results_extraction[features_columns] \n",
    "dataframe_cleaned.insert(0, 'patient', patient)\n",
    "dataframe_cleaned.insert(1, 'sequence', sequence)\n",
    "dataframe_cleaned.insert(2, 'segmentation', segtype)\n",
    "\n",
    "display(dataframe_cleaned)\n",
    "\n",
    "# Now you can easily select a line of set of features for a patient sequence for a specific segmentations: ie\n",
    "\n",
    "features_p1_t1_full =  dataframe_cleaned.iloc[0, 3:].to_numpy()\n",
    "features_p2_t1_full =  dataframe_cleaned.iloc[16, 3:].to_numpy()\n",
    "\n",
    "\n",
    "# Help iloc[row_idx, columns_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tehgz6HpMLAT"
   },
   "source": [
    "**Exercice:** Plot the two feature vectors and the difference. Feature values have a wide range of magnitudes and will be plotted on a log scale. You can have fun and change the input modality or the segmentation type.\n",
    "Plot will be composed of three subplot, first is features from patient1 from a modality_type1 for segtype1. Second is features from patient2 from a modality_type2 for segtype2. Third subplot is the difference between the two features vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_jOGAHfMLAV",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Write your code Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iukwQbsCMLAc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Solution {display-mode: \"form\"}\n",
    "# %load solutions_exercices/plot_features_vector.py\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, squeeze=True, figsize=(20, 10))\n",
    "\n",
    "axes[0].plot(features_p1_t1_full, label='features from patient 1 for the full segmentation in T1 modality', color='red')\n",
    "axes[0].plot(features_p2_t1_full, label='features from patient 2 for the full segmentation in T1 modality', color='green')\n",
    "axes[0].set_yscale('symlog')\n",
    "axes[0].set_ylabel('symlog')\n",
    "axes[0].set_xlabel('feature id')\n",
    "axes[0].set_xticklabels(features_columns, rotation='vertical')\n",
    "axes[0].set_title(\"Features from Patient 1 for the full segmentation in T1 modality\")\n",
    "\n",
    "axes[1].plot(features_p1_t1_full - features_p2_t1_full)\n",
    "axes[1].set_yscale('symlog')\n",
    "axes[1].set_ylabel('symlog')\n",
    "axes[1].set_xlabel('feature id')\n",
    "axes[1].set_xticks(range(len(features_p1_t1_full)))\n",
    "axes[1].set_xticklabels(features_columns, rotation=90)\n",
    "axes[1].set_title(\"Difference\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHTfHZ_8MLAo"
   },
   "source": [
    "## Step 2: Exploring and Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2kRLi2qMLAr"
   },
   "source": [
    "The first step in machine learning is to understand your data, so that you can identify a good target to learn and choose an appropriate learning technique among many possible families of candidates.\n",
    "\n",
    "The previous work of this notebook has been applied on up to two patients, with already significant time to process all of the data into features. Since our time in this practical session is limited, the features on the entire BraTS dataset has been extracted beforehand and saved into a csv file which should be available locally in _./data/radiomics_analysis_cleaned.csv_. This file contains one row per patient per input modality (T1, T1ce, T2, flair) per type of tumor ROI (4*4=16 rows per patient).\n",
    "\n",
    "Let's explore the data !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KD2nQxUSMLAv"
   },
   "source": [
    "### Load datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_l2SfxwMLAx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "path_dataset = './data/radiomics_analysis_cleaned.csv'\n",
    "\n",
    "data = pd.read_csv(path_dataset)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUaUlXE7MLA3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can generate a full dataframe which representes all the features for a patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDfMRvApMLA5",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_features_df = data.pivot_table(index=['patient', 'label'],\n",
    "                                    columns=['sequence', 'segmentation'],\n",
    "                                    values=data.columns[4:])\n",
    "full_features_df.columns = ['_'.join(col).strip() for col in full_features_df.columns.values]\n",
    "full_features_df.reset_index(level=1, inplace=True)\n",
    "display(full_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV6f83jVMLBC",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('repartition by class:\\n',  full_features_df['label'].value_counts())\n",
    "print('numbers of total features: ', len(full_features_df.columns) -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPvaNgEtMLBJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pairwise Join Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQGY7An_MLBM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see the join distribution of any pair of columns/attributes/variables/features by using the pairplot function offered by Seaborn, which is based on Matplotlib. We're only gonna plot the first 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYJ61n3WMLBO",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
    "d = data[(data['sequence']=='t1ce')  & (data['segmentation']=='full')].iloc[:, 3:9] \n",
    "\n",
    "sns.pairplot(d, hue=\"label\", height=2.5, )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44IbRa5jZBUH"
   },
   "source": [
    "#### Interpretation\n",
    "When observing the produced plots, it can be seen that some pairs of features seem te bring high value towards discrimintating between LGG (in orange) and HGG (in blue). For instance, the plot at the second line and first column between the features 10Percentile (10th percentile of image intensities) and 90Percentile (idem with 90th) seem to cluster both cancer subtypes into fuzzy clusters. Multiple lines could be drawn on the graph and would yield performance which is expected to outperform randomness. In these 2D plots, a line is equivalent to a hyperplane (i.e. a plane whose dimension is one less than the dimension of the vectorial space); in other words, any line draw on a 2D plot between two features can be seen as a linear function solution of the classification problem. A decision system can be extracted from a line itself obtained by interrogating the data such as in this plot, and would essentially classify an MRI based on a hyperplance of the projections of the images into a two-dimensional space of features (the space {10Percentile, 90Percentile}). Multi-dimensional machine learning such as linear functions on high dimensional feature spaces with more than 2 features essentially perform the same method, by trying to fit a hyperplance based on a training set such that the classes are separated as much as possible. It is notworthy that rigourous machine learning should involve a hold-out testing set such as to challenge any extracted rule, would it be a line between a space of 2 vectors or any parametrized algorithm such as artificial neural networks, on data samples which have not been used to extract such decision system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8e2cFiE-MLBU"
   },
   "source": [
    "### Plot features as a heatmap¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrrqnTRYMLBW"
   },
   "source": [
    "Showing the pairwise join distributions may still be mind-boggling when we have a lot of variables in the dataset. Sometimes, we can just plot the correlation matrix to quantify the linear relationship between variables.\n",
    "\n",
    "A heat map gives the correlation of features to each other, red indicating positive correlation, and blue negative one. A heatmap may be clustered to show groupings of features that are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xEdc4yjMLBY",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
    "d = data[(data['sequence']=='t1ce')  & (data['segmentation']=='full')].iloc[:, 3:] # the full feature one is too big\n",
    "\n",
    "# create the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Set up the matplotlib figure, make it big!\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(corr, vmax=.8, square=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcqK1vLyMLBg"
   },
   "source": [
    "### Cluster the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vd-i5DqtMLBk"
   },
   "source": [
    "Though useful, heatmaps tell a much better story if the features are clustered. Here we will take a smaller subset of the features and cluster them. In this dendrogram, there are 2 major groups, and many smaller groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgqKOQgEMLBm",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Choose a subset of features for clustering\n",
    "dd = d.iloc[:,3:50]\n",
    "\n",
    "pp = sns.clustermap(dd.corr(), linewidths=.5, figsize=(13,13))\n",
    "_ = plt.setp(pp.ax_heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de TP2_features_extraction_and_visualization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
