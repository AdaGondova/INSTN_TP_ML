{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBg9cIps0hJd"
   },
   "source": [
    "Alexandre CARRE*, Marvin LEROUSSEAU, Enzo BATTISTELLA <img align=\"right\" width=\"400\" height=\"40\" src=\"../images/epu_ia_logo.png\"> <br> *alexandre.carre@gustaveroussy.fr (Notebook conception) <br> marvin.lerousseau@gustaveroussy.fr (Notebook revision) <br> enzo.battistella@gustaveroussy.fr (Notebook revision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25wGLyTo0hJn"
   },
   "source": [
    "# TP1: IMAGING DATAS PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "358rDTzn0hJu"
   },
   "source": [
    "In this notebook you will learn how to process brain images before extracting data from it. First, download necessary materials for the afternoon practical sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-5MyC-l5Bbl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TP2'...\r\n",
      "remote: Invalid username or password.\r\n",
      "fatal: Authentication failed for 'https://github.com/EPU-IA-2020/TP2.git/'\r\n",
      "[Errno 2] No such file or directory: 'TP2/'\n",
      "/media/acarre/Data/PythonProjects/TP2/version_google_colab\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Alxaline/EPU-IA-2021.git\n",
    "%cd EPU-IA-2021/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-s03LiuHFkpx"
   },
   "source": [
    "Ensure GPU is enabled in Google Colaboratory for further processing (otherwise, enabling GPU later will reboot the running session):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtwx_iHMFuan"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found. Enable GPU in Google colaboratory: \"Modifier\" -> \"Paramètres du notebook\" -> Sélectionner \"GPU\" dans \"Accélerateur matériel\" puis relancer le notebook.')\n",
    "print('Found GPU at: {}. All good!'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYkAKsD70hJz"
   },
   "source": [
    "### Data Description\n",
    "\n",
    "Gliomas are primary brain tumours that start in glial cells. Gliomas can be classified into different histopathologic grades according to World Health Oraganization (WHO) grading system which represents malignancy. Gliomas can be low-grade \"LGG\" (slow-growing) or high-grade \"HGG\" (fast-growing).\n",
    "It is important to differentiate HGG from LGG for assessing tumor progression and therapy planning (Louis et al., 2007).\n",
    "The notebooks aim is to present key concepts to predict the grades of Gliomas using Radiomics imaging features.\n",
    "Radiomics is a method capable of comprehensive quantification of tumor phenotypes by extracting a large number of quantitative imaging features.This quantitative analysis method can characterize tumor property in a non-invasive manner and it also can be used as a powerful tool to find biomarker that predict the diagnosis and prognosis of disease along with other clinical parameters. \n",
    "\n",
    "This dataset comes from a Multimodal Brain Tumor Segmentation Challenge which started in 2012 and is still running today.\n",
    " \n",
    "All BraTS multimodal scans are available as NIfTI files (.nii.gz) and describe a) T1 and b) post-contrast T1-weighted (T1Gd), c) T2-weighted (T2), and d) T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes, and were acquired with different clinical protocols and various scanners from multiple (n=19) institutions.\n",
    "\n",
    "All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the Gd-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper (1) and in the latest BraTS summarizing paper (2). The provided data are distributed after their pre-processing, i.e. **co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped**.\n",
    "\n",
    "Following radiological assessment of both the Glioblastoma Multiforme (TCGA-GBM, n=262) and the Low-Grade-Glioma (TCGA-LGG, n=199) collections, Bakas, Spyridon, et al. (3) identified 135 and 108 pre-operative mMRI scans, respectively. This is the numbers of samples that we will used for machine learning. For this part, you will have acces to 10 patients with LGG and 10 patients with GBM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQS0wugm0hJ9"
   },
   "source": [
    "### Installation of python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgoRN3650hKF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install SimpleITK numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMzlqZIe0hKc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Explore images of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "434-ympQ0hKg"
   },
   "source": [
    "In this step, the goal will be to visualize the different MRI imaging sequences associated with the tumor segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-pBoHGm0hKk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1) Load the fifth types of images available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2_7OX2m0hKp"
   },
   "source": [
    "- T1\n",
    "- T1ce\n",
    "- T2\n",
    "- flair\n",
    "- seg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipetY2iH0hKt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_nii(img_path):\n",
    "    \"\"\"\n",
    "    Function to read a NIfTI image from a filepath and return a nD array.\n",
    "    :param img_path: file path of the image to be read\n",
    "    :return: nD array\n",
    "    \"\"\"\n",
    "    return sitk.GetArrayFromImage(sitk.ReadImage(img_path)) # sitk: z,y,x\n",
    "\n",
    "\n",
    "# function to read one subject data\n",
    "def create_data_one_subject(src, count, image_type):\n",
    "    \"\"\"\n",
    "    Function to read one subject data from the general input directory specifying by the count number and image_type\n",
    "    :param src: general input directory of all data\n",
    "    :param count: patient to be read (same order as the glob function walk in the path)\n",
    "    :param image_type: specify the image type to be read, can be 't1ce', 't1', 'flair', 't2', 'seg'\n",
    "    :return: a dict for the 'seg' with key as type of seg and value as nD array. For image a nD array\n",
    "    \"\"\"\n",
    "    # add check range of count (depend of numbers of samples)\n",
    "    files = glob.glob(os.path.join(src, '**/*{}.nii.gz'.format(image_type)), recursive=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError('No .nii.gz data were found in %s' % os.path.join(os.path.join(src, '**')))\n",
    "    k = (len(files) - count) - 1\n",
    "    file = files[k]\n",
    "    print('Processing---', os.path.basename(file))\n",
    "\n",
    "    if any(x in image_type.lower() for x in ['t1ce', 't1', 'flair', 't2']):\n",
    "        return read_nii(file)\n",
    "\n",
    "    if 'seg' in image_type.lower():\n",
    "        label_full, label_nec, label_core, label_et = [], [], [], []\n",
    "        for label_num in [1, 2, 4, 5]:\n",
    "            img = read_nii(file)\n",
    "            if label_num == 5:\n",
    "                img[img != 0] = 1  # Region 1 => 1+2+3+4 complete tumor\n",
    "                label_full = img\n",
    "            if label_num == 1:\n",
    "                img[img != 1] = 0  # only left necrosis\n",
    "                label_nec = img\n",
    "            if label_num == 2:\n",
    "                img[img == 2] = 0  # turn edema to 0\n",
    "                img[img != 0] = 1  # only keep necrosis, ET, NET = Tumor core\n",
    "                label_core = img\n",
    "            if label_num == 4:\n",
    "                img[img != 4] = 0  # only left ET\n",
    "                img[img == 4] = 1\n",
    "                label_et = img\n",
    "        return {'label_full': label_full, 'label_nec': label_nec,\n",
    "                'label_core': label_core, 'label_et': label_et}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqt-x7ZX0hK9"
   },
   "source": [
    "**Exercice:** From functions above <code>create_data_one_subject</code>, read all types of images ('t1ce', 't1', 'flair', 't2', 'seg'). The variable name will have the same name as the image type. The source directory for src parameters is '/data/preprocessed/'. The count which allow you to select the patient need a range value between 0 and 20.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5YzCqEU0hLA"
   },
   "outputs": [],
   "source": [
    "src = './data/preprocessed/'\n",
    "\n",
    "## Write your code Here\n",
    "t1 = \n",
    "t1ce =\n",
    "t2 = \n",
    "flair = \n",
    "seg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAP0vhoz0hLO"
   },
   "outputs": [],
   "source": [
    "#@title Solution {display-mode: \"form\"}\n",
    "%load solutions_exercices/read_one_subject.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jnbrvgl0hLb"
   },
   "source": [
    "### 3) Choose the orientation view and the slice number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpRBClq-0hLf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "slice_number = 105\n",
    "view = 'axial' # can be 'coronal', sagittal, 'axial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h049tcE20hLo"
   },
   "source": [
    "### 4) View Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYKaQa1t0hLt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if view == 'axial':\n",
    "    axial = int(slice_number)\n",
    "    coronal = slice(None)\n",
    "    sagittal = slice(None)\n",
    "if view == 'coronal':\n",
    "    axial = slice(None)\n",
    "    coronal = int(slice_number)\n",
    "    sagittal = slice(None)\n",
    "if view == 'sagittal':\n",
    "    axial = slice(None)\n",
    "    coronal = slice(None)\n",
    "    sagittal = int(slice_number)  \n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(241)\n",
    "plt.title('T1')\n",
    "plt.axis('off')\n",
    "plt.imshow(t1[axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(242)\n",
    "plt.title('T2')\n",
    "plt.axis('off')\n",
    "plt.imshow(t2[axial, coronal, sagittal],cmap='gray')\n",
    "    \n",
    "plt.subplot(243)\n",
    "plt.title('Flair')\n",
    "plt.axis('off')\n",
    "plt.imshow(flair[axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(244)\n",
    "plt.title('T1ce')\n",
    "plt.axis('off')\n",
    "plt.imshow(t1ce[axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(245)\n",
    "plt.title('Ground Truth (full)')\n",
    "plt.axis('off')\n",
    "plt.imshow(seg['label_full'][axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(246)\n",
    "plt.title('Ground Truth (nec)')\n",
    "plt.axis('off')\n",
    "plt.imshow(seg['label_nec'][axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(247)\n",
    "plt.title('Ground Truth (core)')\n",
    "plt.axis('off')\n",
    "plt.imshow(seg['label_core'][axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.subplot(248)\n",
    "plt.title('Ground Truth (et)')\n",
    "plt.axis('off')\n",
    "plt.imshow(seg['label_et'][axial, coronal, sagittal],cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlW_3uEQ0hL4"
   },
   "source": [
    "## Step 2: Images preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09jmzdKg0hL9"
   },
   "source": [
    "As mentionned above, all images in the BratS dataset have already gone through some pre-processing steps.\n",
    "To show the different preprocessing steps, we will use a raw data of BRATs and then:\n",
    "- Correct magnetic bias field\n",
    "- Resample to 1mm x 1mm x 1mm\n",
    "- Skull-strip data\n",
    "- Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jho3JLgx0hMC"
   },
   "source": [
    "###  Installation of needed package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrtC6HGK0hMF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Installation of Ants\n",
    "\n",
    "ANTs is popularly considered as a state-of-the-art medical image registration and segmentation toolkit (4). This library is coded in C++, this is why we will install it as a binary file. So, we won't use a python Wrapper and directly execute the command line with the !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnmxedDo0hMJ"
   },
   "source": [
    "1) Run the following command to download the binary of ANTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1BjpO-k0hMN"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "function gdrive_download () {\n",
    " CONFIRM=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \"https://docs.google.com/uc?export=download&id=$1\" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')\n",
    " wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$CONFIRM&id=$1\" -O $2\n",
    " rm -rf /tmp/cookies.txt\n",
    "}\n",
    "gdrive_download 1R0e4r9XmEQxTj_RGw8rpOsyQuqW_4Ubj ANTs-28-03-2019.7z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQ1ygaBu0hMW"
   },
   "source": [
    "2) Extract it using 7z, then copy the entire contents of the newly created bin folder to /usr/local/bin/, and finally test the installation by running _which_ command that should output the full path to antsRegistration such as _/usr/local/bin/antsRegistration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-e-K1l20hMb"
   },
   "outputs": [],
   "source": [
    "!7z x ANTs-28-03-2019.7z\n",
    "!cp bin/* /usr/local/bin\n",
    "!which antsRegistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ifnfvbYU0hNH"
   },
   "source": [
    "#### Installation of HD-BET\n",
    "\n",
    "HD-BET is a brain extraction tool based on deep learning (5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hePlxazz0hNJ"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/MIC-DKFZ/HD-BET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZbq456V0hNS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "install_path = os.path.join(os.getcwd(), 'HD-BET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyCNz64r0hNa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -e \"$install_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdQEAvGq0hNl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1) Load a sample of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5IpWEM50hNp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data_path = './data/raw/GBM/TCGA-02-0027/TCGA-02-0027_GADO.nii.gz'\n",
    "raw_data = read_nii(raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ea_ZcZ000hN0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2) Bias field correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FszOlsGv0hN2"
   },
   "source": [
    "Bias field signal is a low-frequency and very smooth signal that corrupts MRI images specially those produced by old MRI (Magnetic Resonance Imaging) machines. Image processing algorithms such as segmentation, texture analysis or classification that use the graylevel values of image pixels will not produce satisfactory results. A pre-processing step is needed to correct for the bias field signal before submitting corrupted MRI images to such algorithms (6). The version used here is a variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm proposed for bias field correction (N4ITK) (7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9hpigwB0hN4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bias_field_correct_image_path = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4.nii.gz')\n",
    "bias_field_path = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_bias_field.nii.gz')\n",
    "\n",
    "!N4BiasFieldCorrection -d 3 -i  \"$raw_data_path\" -s 3 -c [10x10x10x10, 1e-7] -b [200] -o [\"$bias_field_correct_image_path\", \"$bias_field_path\"]  -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8CKeQ3T0hOC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Display datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0e9lLFA0hOF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load datas\n",
    "raw_data = read_nii(raw_data_path)\n",
    "bias_field_correct_image = read_nii(bias_field_correct_image_path)\n",
    "bias_field = read_nii(bias_field_path)\n",
    "image_difference = raw_data - bias_field_correct_image\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.imshow(raw_data[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title('Bias field')\n",
    "plt.axis('off')\n",
    "plt.imshow(bias_field[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.title('Bias field corrected image')\n",
    "plt.axis('off')\n",
    "plt.imshow(bias_field_correct_image[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.title('Image difference')\n",
    "plt.axis('off')\n",
    "plt.imshow(image_difference[80, :, :],cmap='gray')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnC5XLJg0hOM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3) Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4mSHxu00hOP"
   },
   "source": [
    "Voxel size resampling is a vital preprocessing step for datasets that have variable voxel sizes. Specifically, isotropic voxel size is required for some texture features extraction. Down-sampling to larger voxel dimensions will lead to information loss. On the contrary, up-sampling may add artifical information. It is still unclear which one is better and perhaps the best way to evaluate this is to base the judgement on the model's performances (8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgnpDVbq0hOR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resampled_image_path_1mm = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_1mm.nii.gz')\n",
    "resampled_image_path_2mm = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_2mm.nii.gz')\n",
    "resampled_image_path_6mm = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_6mm.nii.gz')\n",
    "\n",
    "!ResampleImage 3 \"$bias_field_correct_image_path\" \"$resampled_image_path_1mm\" 1x1x1 0 4 \n",
    "!ResampleImage 3 \"$bias_field_correct_image_path\" \"$resampled_image_path_2mm\" 2x2x2 0 4 \n",
    "!ResampleImage 3 \"$bias_field_correct_image_path\" \"$resampled_image_path_6mm\" 6x6x6 0 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeGhODEc0hOY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Display datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ncQ1W0E0hOZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load datas\n",
    "raw_data = read_nii(raw_data_path)\n",
    "resampled_image_1mm = read_nii(resampled_image_path_1mm)\n",
    "resampled_image_2mm = read_nii(resampled_image_path_2mm)\n",
    "resampled_image_6mm = read_nii(resampled_image_path_6mm)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.imshow(raw_data[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title('Bias field corrected + \\n Resampled 1 mm')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm[120, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.title('Bias field corrected +  \\n Resampled 2 mm')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_2mm[60, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.title('Bias field corrected +  \\n Resampled 6 mm')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_6mm[20, :, :],cmap='gray')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiDxQKvT0hOh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4) Skull-Stripping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NReimjG0hOm"
   },
   "source": [
    "The skull stripping method is an important area of research in brain image processing applications. It acts as a preliminary step in numerous medical applications as it increases speed and accuracy of diagnosis in manifold. It removes non-cerebral tissues like skull, scalp, and dura from brain images (9). It will allow to remove skull where the range of intensities variation is high and base the subsequent normalization only on brain tissues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnA2vEq80hOq",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skull_stripped_image_path = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_1mm_ss.nii.gz')\n",
    "\n",
    "!hd-bet -i \"$resampled_image_path_1mm\" -o \"$skull_stripped_image_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py5zJWo90hOx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Display datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "447BcWft0hO0"
   },
   "outputs": [],
   "source": [
    "# Load datas\n",
    "raw_data = read_nii(raw_data_path)\n",
    "resampled_image_1mm = read_nii(resampled_image_path_1mm)\n",
    "resampled_image_1mm_ss = read_nii(skull_stripped_image_path)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.imshow(raw_data[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Bias field corrected + \\n Resampled 1 mm')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm[120, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Bias field corrected +  \\n Resampled 1 mm + Skull-stripped')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm_ss[120, :, :],cmap='gray')\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpJ-N2hW0hO7"
   },
   "source": [
    "### 5) Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUrJK3dg0hO9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Intensity normalization is an important preprocessing step in brain magnetic resonance image (MRI) analysis. During MR image acquisition, different scanners or parameters would be used for scanning different subjects or the same subject at a different time, which may result in large intensity variations. This intensity variation will greatly undermine the performance of subsequent MRI processing and population analysis, such as image registration, segmentation, and tissue volume measurement (10).\n",
    "\n",
    "The method used here is a simple method: Z-score normalization uses the brain mask B corresponding to the image I to determine the mean and standard deviation of the intensities inside the brain mask, that is: \n",
    "$$ \\mu = \\frac{1}{|B|} \\sum_{\\mathbf b \\in B} I(\\mathbf b) \\quad \\text{and} \\quad\n",
    "\\sigma = \\sqrt{\\frac{\\sum_{\\mathbf b \\in B} (I(\\mathbf b) - \\mu)^2}{|B|-1}} $$\n",
    "Then the Z-score normalized image is\n",
    "$$ I_{\\text{z-score}}(\\mathbf x) = \\frac{I(\\mathbf x) - \\mu}{\\sigma}. $$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpssTXmq0hO_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "def zscore_normalize(img_path, mask=None):\n",
    "    \"\"\"\n",
    "    Function to Z-Score normalize an image from an image filepath. It will normalize the target \n",
    "    image by subtracting the mean of the whole brain and dividing by the standard deviation.\n",
    "    :param img_path: target MR brain image path\n",
    "    :param mask: brain mask path for img\n",
    "    :return: Normalized image in sitk format\n",
    "    \"\"\"\n",
    "    img = sitk.ReadImage(img_path)\n",
    "    img_data = sitk.GetArrayFromImage(img)\n",
    "    origin, direction, spacing = img.GetOrigin(), img.GetDirection(), img.GetSpacing()\n",
    "    if mask is not None and isinstance(mask, str):\n",
    "        mask_data = read_nii(mask)\n",
    "    elif mask == 'nomask':\n",
    "        mask_data = img_data == img_data\n",
    "    else:\n",
    "        mask_data = img_data > img_data.mean()\n",
    "    logical_mask = mask_data == 1  # force the mask to be logical type\n",
    "    mean = img_data[logical_mask].mean()\n",
    "    std = img_data[logical_mask].std()\n",
    "    normalized_data = sitk.GetImageFromArray((img_data - mean) / std)\n",
    "    normalized_data.SetOrigin(origin)\n",
    "    normalized_data.SetDirection(direction)\n",
    "    normalized_data.SetSpacing(spacing)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49-stjyo0hPG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_path = skull_stripped_image_path\n",
    "mask_path = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_1mm_ss_mask.nii.gz')\n",
    "\n",
    "normalized_image = zscore_normalize(img_path=skull_stripped_image_path)\n",
    "\n",
    "normalized_image_path = os.path.join(os.path.dirname(raw_data_path), os.path.splitext(os.path.splitext(os.path.basename(raw_data_path))[0])[0] + '_n4_resampled_1mm_ss_normalize.nii.gz')\n",
    "\n",
    "# write image\n",
    "sitk.WriteImage(normalized_image, normalized_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCYjdE2B0hPN"
   },
   "source": [
    "#### Display datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQwlKFcu0hPO"
   },
   "outputs": [],
   "source": [
    "# Load datas\n",
    "raw_data = read_nii(raw_data_path)\n",
    "resampled_image_1mm = read_nii(resampled_image_path_1mm)\n",
    "resampled_image_1mm_ss = read_nii(skull_stripped_image_path)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.imshow(raw_data[80, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title('Bias field corrected + \\n Resampled 1 mm')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm[120, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.title('Bias field corrected +  \\n Resampled 1 mm + Skull-stripped')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm_ss[120, :, :],cmap='gray')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.title('Bias field corrected +  \\n Resampled 1 mm + only skull')\n",
    "plt.axis('off')\n",
    "plt.imshow(resampled_image_1mm[120, :, :] - resampled_image_1mm_ss[120, :, :],cmap='gray')\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeIeoiys0hPV"
   },
   "source": [
    "# References\n",
    "(1): Menze, Bjoern H., et al. \"The multimodal brain tumor image segmentation benchmark (BRATS).\" IEEE transactions on medical imaging 34.10 (2014): 1993-2024.\n",
    "\n",
    "(2): Bakas, Spyridon, et al. \"Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge.\" arXiv preprint arXiv:1811.02629 (2018).\n",
    "\n",
    "(3): Bakas, Spyridon, et al. \"Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features.\" Scientific data 4 (2017): 170117.\n",
    "\n",
    "(4): https://github.com/ANTsX/ANTs\n",
    "\n",
    "(5): Isensee, Fabian, et al. \"Automated brain extraction of multi-sequence MRI using artificial neural networks.\" arXiv preprint arXiv:1901.11341 (2019).\n",
    "\n",
    "(6): Juntu, Jaber, et al. \"Bias field correction for MRI images.\" Computer Recognition Systems. Springer, Berlin, Heidelberg, 2005. 543-551.\n",
    "\n",
    "(7): Tustison, Nicholas J., et al. \"N4ITK: improved N3 bias correction.\" IEEE transactions on medical imaging 29.6 (2010): 1310.\n",
    "\n",
    "(8): Li, Ruijiang, et al., eds. Radiomics and Radiogenomics: Technical Basis and Clinical Applications. CRC Press, 2019.\n",
    "\n",
    "(9): Roy, Shaswati, and Pradipta Maji. \"A simple skull stripping algorithm for brain MRI.\" 2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR). IEEE, 2015.\n",
    "\n",
    "(10): Sun, Xiaofei, et al. \"Histogram-based normalization technique on human brain magnetic resonance images from different acquisitions.\" Biomedical engineering online 14.1 (2015): 73."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de TP1_imaging_datas_preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}